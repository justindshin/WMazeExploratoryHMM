{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jdshin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: The mpl_toolkits.axes_grid module was deprecated in version 2.1. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist provies the same functionality instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct\n",
    "import scipy.io\n",
    "import nelpy as nel\n",
    "import nelpy.io\n",
    "import nelpy.plotting as npl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import linfields\n",
    "linmat = scipy.io.loadmat('H:\\Single_Day_WTrack\\JS15_direct\\JS15linfields01.mat', \n",
    "                       struct_as_record=False, squeeze_me=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_linfield(linmat):\n",
    "    linfielddata = []\n",
    "\n",
    "    data = linmat['linfields']\n",
    "    for epidx, da in enumerate(data):\n",
    "        for tetidx, te in enumerate(da): \n",
    "            if isinstance(te, np.ndarray):\n",
    "                for cellidx, cell in enumerate(te):\n",
    "                    if len(cell) < 20:\n",
    "                        linfielddata.append({})\n",
    "                        linfielddata[-1]['Epoch'] = epidx\n",
    "                        neuron_idx = (tetidx, cellidx)\n",
    "                        linfielddata[-1]['Tetrode'] = tetidx\n",
    "                        linfielddata[-1]['Cell'] = cellidx\n",
    "                        if len(cell) == 4:\n",
    "                            outl = cell[0]; inl = cell[1]; outr = cell[2]; inr = cell[3] \n",
    "                            linfielddata[-1].update({'outleft':outl})\n",
    "                            linfielddata[-1].update({'inleft':inl})\n",
    "                            linfielddata[-1].update({'outright':outr})\n",
    "                            linfielddata[-1].update({'inright':inr})\n",
    "                    else:  \n",
    "                         if cellidx == 0:\n",
    "                            linfielddata.append({})\n",
    "                            linfielddata[-1]['Epoch'] = epidx\n",
    "                            neuron_idx = (tetidx, cellidx)\n",
    "                            linfielddata[-1]['Tetrode'] = tetidx\n",
    "                            linfielddata[-1]['Cell'] = cellidx\n",
    "                            outl = te[0]; inl = te[1]; outr = te[2]; inr = te[3] \n",
    "                            linfielddata[-1].update({'outleft':outl})\n",
    "                            linfielddata[-1].update({'inleft':inl})\n",
    "                            linfielddata[-1].update({'outright':outr})\n",
    "                            linfielddata[-1].update({'inright':inr})\n",
    "                         else:\n",
    "                            continue\n",
    "                    \n",
    "    return linfielddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfields = load_linfield(linmat)\n",
    "\n",
    "#Get rid of entries that that no linfields\n",
    "linfields = []\n",
    "for dat in lfields:\n",
    "    lfielddata_cell = dat\n",
    "    if  len(lfielddata_cell) > 3:\n",
    "        linfields.append({})\n",
    "        linfields[-1] = lfielddata_cell\n",
    "        del lfielddata_cell\n",
    "    else:\n",
    "        del lfielddata_cell\n",
    "        continue\n",
    "        \n",
    "del dat\n",
    "del lfields\n",
    "del linmat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca1tet = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25] #JS15\n",
    "#pfctet = [0, 1, 2, 3, 14, 15, 16, 17, 18, 19, 27, 28, 29, 30, 31]  #JS15\n",
    "#pfctet = [0, 1, 2, 3, 4, 15, 16, 17, 18, 19, 26, 28, 29, 30, 31]; #ER1\n",
    "#pfctet = [0, 1, 2, 3, 12, 13, 14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 30, 31] #JS17\n",
    "epochlist = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "#Get ca1 linfields\n",
    "ca1_linfields = []\n",
    "for ep in epochlist:\n",
    "    for tet in ca1tet:\n",
    "        for t, field in enumerate(linfields):\n",
    "            if field['Epoch'] == ep:\n",
    "                if field['Tetrode'] == tet:\n",
    "                    field['Area'] = 'CA1'\n",
    "                    ca1_linfields.append({})\n",
    "                    ca1_linfields[-1] = field\n",
    "                    linfields[t]['Area'] = 'CA1'\n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "del field\n",
    "del tet\n",
    "del ca1tet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match cells across eps\n",
    "matchidx = []\n",
    "for x in ca1_linfields:\n",
    "    if x['Epoch'] == 1:\n",
    "        cell = x['Cell']\n",
    "        tet = x['Tetrode'] \n",
    "        matchidx.append({})\n",
    "        matchidx[-1]['Cell'] = cell\n",
    "        matchidx[-1]['Tetrode'] = tet\n",
    "\n",
    "cellidx=[]        \n",
    "for match in matchidx:\n",
    "    c = match['Cell']\n",
    "    t = match['Tetrode']\n",
    "    idx = [t, c]\n",
    "    cellidx.append(idx)\n",
    "    cellidx.sort()\n",
    "    \n",
    "eparray = [1]  \n",
    "allep_cellidx = []\n",
    "for ep in eparray: \n",
    "    for c in cellidx:\n",
    "        cellinep_count = []\n",
    "        for sp in ca1_linfields:\n",
    "            if sp['Tetrode'] == c[0] and sp['Cell'] == c[1]:\n",
    "                cellinep_count.append(sp)\n",
    "        if len(cellinep_count) == 8: #dirty way to specify number of epochs to match over\n",
    "            allep_cellidx.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of all nan spatial bins across all trajectories (usually common in first epochs)\n",
    "ca1_linfields_nonan = []\n",
    "for p in ca1_linfields:\n",
    "    isnan = []\n",
    "    pp = p\n",
    "    inleft = p['inleft'][:,4]\n",
    "    inleftnanidx = np.argwhere(np.isnan(inleft))\n",
    "    inright = p['inright'][:,4]\n",
    "    inrightnanidx = np.argwhere(np.isnan(inright))\n",
    "    outleft = p['outleft'][:,4]\n",
    "    outleftnanidx = np.argwhere(np.isnan(outleft))\n",
    "    outright = p['outright'][:,4]\n",
    "    outrightnanidx = np.argwhere(np.isnan(outright))\n",
    "    \n",
    "    isnan = inleftnanidx\n",
    "    isnan = np.concatenate((isnan, inrightnanidx),axis=0)\n",
    "    isnan = np.concatenate((isnan, outleftnanidx),axis=0)\n",
    "    isnan = np.concatenate((isnan, outrightnanidx),axis=0)\n",
    "    isnanallidx = isnan\n",
    "    \n",
    "    isnanallidx = np.sort(isnanallidx)\n",
    "   \n",
    "    pp['inleft'] = np.delete(inleft, isnanallidx)\n",
    "    pp['inright'] = np.delete(inright, isnanallidx)\n",
    "    pp['outleft'] = np.delete(outleft, isnanallidx)\n",
    "    pp['outright'] = np.delete(outright, isnanallidx) \n",
    "    \n",
    "    ca1_linfields_nonan.append({})\n",
    "    ca1_linfields_nonan[-1] = pp\n",
    "    del isnan\n",
    "    del isnanallidx\n",
    "    del pp\n",
    "    del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate new linfields with trajectories with same lengths\n",
    "fixed_ca1_linfields = []\n",
    "\n",
    "for l in ca1_linfields_nonan:\n",
    "    left_length = len(l['inleft'])\n",
    "    right_length = len(l['inright']) \n",
    "    \n",
    "    if left_length > right_length:\n",
    "        new_length = left_length\n",
    "        newr_x = np.linspace(0, len(l['inleft']), new_length)\n",
    "        newr_yin = interp.interp1d(np.arange(right_length), l['inright'], kind='linear', fill_value='extrapolate')(newr_x)    \n",
    "        newr_yout = interp.interp1d(np.arange(right_length), l['outright'], kind='linear', fill_value='extrapolate')(newr_x)  \n",
    "        l['inright'] = newr_yin\n",
    "        l['outright'] = newr_yout\n",
    "        \n",
    "        fixed_ca1_linfields.append({})\n",
    "        fixed_ca1_linfields[-1] = l\n",
    "\n",
    "    elif left_length < right_length:\n",
    "        new_length = right_length\n",
    "        newl_x = np.linspace(0, len(l['inleft']), new_length)\n",
    "        newl_yin = interp.interp1d(np.arange(left_length), l['inleft'], kind='linear', fill_value='extrapolate')(newl_x)    \n",
    "        newl_yout = interp.interp1d(np.arange(left_length), l['outleft'], kind='linear', fill_value='extrapolate')(newl_x) \n",
    "        l['inleft'] = newl_yin\n",
    "        l['outleft'] = newl_yout\n",
    "        \n",
    "        fixed_ca1_linfields.append({})\n",
    "        fixed_ca1_linfields[-1] = l\n",
    "\n",
    "    elif left_length == right_length:\n",
    "        fixed_ca1_linfields.append({})\n",
    "        fixed_ca1_linfields[-1] = l\n",
    "\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform correlation analysis between all trajectories and shuffled trajectories\n",
    "epochlist = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "maxr_pec_hpc = {'ep1':[],'ep3':[],'ep5':[],'ep7':[],'ep9':[],'ep11':[],'ep13':[],'ep15':[]}\n",
    "pec_hpc = {'ep1':[],'ep3':[],'ep5':[],'ep7':[],'ep9':[],'ep11':[],'ep13':[],'ep15':[]}\n",
    "pec_hpc_shuf = {'ep1':[],'ep3':[],'ep5':[],'ep7':[],'ep9':[],'ep11':[],'ep13':[],'ep15':[]}\n",
    "for ep in epochlist:\n",
    "    for f in fixed_ca1_linfields:\n",
    "        rvals = []\n",
    "        pvals = []\n",
    "        rvals_shuf = []\n",
    "        pvals_shuf = []\n",
    "        t = f['Tetrode']\n",
    "        c = f['Cell']\n",
    "        e = f['Epoch']\n",
    "        if f['Epoch'] == ep:\n",
    "            \n",
    "            r, p = pearsonr(f['inleft'], f['inright']) #get rid of center arm\n",
    "            rvals.append(r)\n",
    "            pvals.append(p)\n",
    "            r, p = pearsonr(f['inleft'], f['outleft'])\n",
    "            rvals.append(r)\n",
    "            pvals.append(p)\n",
    "            r, p = pearsonr(f['inleft'], f['outright'])\n",
    "            rvals.append(r)\n",
    "            pvals.append(p)\n",
    "            r, p = pearsonr(f['inright'], f['outleft'])\n",
    "            rvals.append(r)\n",
    "            pvals.append(p)\n",
    "            r, p = pearsonr(f['inright'], f['outright'])\n",
    "            rvals.append(r)\n",
    "            pvals.append(p)\n",
    "            \n",
    "            r, p = pearsonr(f['outleft'], f['outright']) #get rid of center arm\n",
    "            rvals.append(r)\n",
    "            pvals.append(p)\n",
    "            for c in allep_cellidx:\n",
    "                if f['Tetrode'] == c[0] and f['Cell'] == c[1]:\n",
    "                    maxr = np.nanmax(rvals)\n",
    "                    minp = np.nanmin(pvals)\n",
    "            \n",
    "                    f['rvalues'] = rvals\n",
    "                    f['pvalues'] = pvals\n",
    "                    f['maxp'] = minp\n",
    "                    f['maxr'] = max\n",
    "            \n",
    "                    maxr_pec_hpc['ep' + str(ep)].append(maxr)\n",
    "\n",
    "                    rmean = np.nanmean(rvals)\n",
    "#                    if rmean > 0: #some positive degree of path equiv\n",
    "                    pec_hpc['ep' + str(ep)].append(rmean)\n",
    "#                    else:\n",
    "#                        continue\n",
    "                    #Do shuffling from Frank et al. 2000\n",
    "                    trajtoshuf = [f['inleft'], f['inright'], f['outleft'], f['outright']]\n",
    "                    trajkeys = ['inleft', 'inright', 'outleft', 'outright']\n",
    "                    for shuf in trajtoshuf:\n",
    "                        if len(shuf) % 2 == 0:\n",
    "                            mididx = len(shuf) / 2\n",
    "                            abmirror = shuf[0:int(mididx + 1)]\n",
    "                            abmirror = abmirror.tolist()\n",
    "                            abmirror.reverse()\n",
    "                            cd = shuf[int(mididx + 1):]\n",
    "                            cd = cd.tolist()\n",
    "                            cdab_shuf = cd + abmirror\n",
    "                            if np.mean(cdab_shuf) != 0:\n",
    "                                for key in trajkeys:\n",
    "                                    #take out center stem here for some\n",
    "                                    r_shuf, p_shuf = pearsonr(f[key], cdab_shuf)\n",
    "                                    rvals_shuf.append(r_shuf)\n",
    "                                    pvals_shuf.append(p_shuf)\n",
    "                            else:\n",
    "                                continue\n",
    "                        \n",
    "                        else:\n",
    "                            mididx = int((len(shuf) / 2) + 0.5)\n",
    "                            abmirror = shuf[0:int(mididx + 1)]\n",
    "                            abmirror = abmirror.tolist()\n",
    "                            abmirror.reverse() \n",
    "                            cd = shuf[int(mididx + 1):]\n",
    "                            cd = cd.tolist()\n",
    "                            cdab_shuf = cd + abmirror\n",
    "                            if np.mean(cdab_shuf) != 0:\n",
    "                                for key in trajkeys:\n",
    "                                    r_shuf, p_shuf = pearsonr(f[key], cdab_shuf)\n",
    "                                    rvals_shuf.append(r_shuf)\n",
    "                                    pvals_shuf.append(p_shuf)\n",
    "                            else:\n",
    "                                continue\n",
    "                                \n",
    "                    maxr_shuf = np.nanmax(rvals_shuf)                                                                                    \n",
    "                    pec_hpc_shuf['ep' + str(ep)].append(maxr - maxr_shuf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
